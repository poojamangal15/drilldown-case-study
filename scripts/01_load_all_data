import pandas as pd
from google.cloud import bigquery
from google.oauth2 import service_account

PROJECT_ID = "drilldown-case-study"
RAW = "drilldown_raw"

creds = service_account.Credentials.from_service_account_file("keys/gcp-sa.json")
client = bigquery.Client(project=PROJECT_ID, credentials=creds)

tables = ["companies","contacts","deals","invoices","invoice_lines","products"]

for t in tables:
    path = f"data/{t}.csv"
    df = pd.read_csv(path)
    table_id = f"{PROJECT_ID}.{RAW}.{t}"
    job = client.load_table_from_dataframe(df, table_id)
    job.result()
    print(f"Loaded {len(df):,} rows into {table_id}")
